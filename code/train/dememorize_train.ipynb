{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71425cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "from datasets import load_metric\n",
    "\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPTNeoForCausalLM, AutoModelForCausalLM\n",
    "from datasets import load_dataset\n",
    "# from peft import LoraConfig\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, HfArgumentParser, pipeline\n",
    "\n",
    "from trl import AutoModelForCausalLMWithValueHead, PPOConfig, PPOTrainer, set_seed\n",
    "from trl.core import LengthSampler\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "import time\n",
    "import os\n",
    "import statistics\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "tqdm.pandas()\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "import argparse\n",
    "from evaluate import load\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()\n",
    "from torchmetrics.functional import accuracy\n",
    "from accelerate.tracking import GeneralTracker, on_main_process\n",
    "from typing import Optional\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c50451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##editing wandb api so we can specify parameters such as group, run_name, etc\n",
    "class WandbEd(GeneralTracker):\n",
    "    name = \"wandb\"\n",
    "    requires_logging_directory = False\n",
    "\n",
    "    @on_main_process\n",
    "    def __init__(self, project: str, run_name, group: str, entity: str, config: dict):\n",
    "        self.group = group\n",
    "        self.run_name = run_name\n",
    "        self.project = project\n",
    "        self.config = config\n",
    "        self.entity = entity\n",
    "        run = wandb.init(group = self.group, name = self.run_name, entity = self.entity, project = self.project, config=config)\n",
    "\n",
    "    @property\n",
    "    def tracker(self):\n",
    "        return self.run.run\n",
    "\n",
    "    @on_main_process\n",
    "    def store_init_configuration(self, values: dict):\n",
    "        wandb.config = values\n",
    "\n",
    "    @on_main_process\n",
    "    def log(self, values: dict, step: Optional[int] = None):\n",
    "        wandb.log(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56604ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_sc = {\n",
    "    \"lm_name\": 'facebook/opt-2.7b', ##model name\n",
    "    \"alpha_bleu\": 0.5, ##bleu weight if you want to use multi-objective optimization\n",
    "    \"beta_ppl\": 0.5,   ##perplexity weight if you want to use multi-objective optimization\n",
    "    \"reward_type\": 'bert',   ##reward function type\n",
    "    \"ref_lm_name\": 'facebook/opt-2.7b',  ##ref model name, same as model name\n",
    "    \"cls_model_name\": \"null\", \n",
    "    \"tk_name\": \"lm_extraction\",\n",
    "    \"reward_fn\": 'bert', ##reward function type\n",
    "    \"steps\": 2, \n",
    "    \"batch_size\": 32,\n",
    "    \"forward_batch_size\": 8,\n",
    "    \"ppo_epochs\": 2,   \n",
    "    \"lr\": 1.41e-5,\n",
    "    \"init_kl_coef\":0.2,\n",
    "    \"target\": 6,\n",
    "    \"horizon\":10000,\n",
    "    \"gamma\":1,\n",
    "    \"lam\":0.95,\n",
    "    \"cliprange\": .2,\n",
    "    \"cliprange_value\":.2,\n",
    "    \"vf_coef\":.1, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba7783e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4786ed2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'train'\n",
    "\n",
    "if mode == 'inference':\n",
    "    run_name = config_sc['lm_name']+'_'+config_sc['dataset_type']\n",
    "else:\n",
    "    run_name = config_sc['lm_name']+'_'+'training'\n",
    "\n",
    "wandbed_obj = WandbEd(group=config_sc['lm_name'], project='lm_extraction_defence_exps', entity = \"thesis_projects\", run_name=run_name, config = config_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eea4e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PPOConfig(\n",
    "    model_name='/models--facebook--opt-2.7b/snapshots/397f71a473a150c00f0fe3fc4a2f78ff3ccaf82d',\n",
    "    learning_rate=1.41e-5,\n",
    "    batch_size=32,\n",
    "    forward_batch_size=8,\n",
    "    ppo_epochs = 8,\n",
    "    optimize_cuda_cache=True,\n",
    "    remove_unused_columns = False,\n",
    "    log_with=wandbed_obj,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f62219",
   "metadata": {},
   "outputs": [],
   "source": [
    "sacrebleu = load_metric('sacrebleu')\n",
    "bertscore = load(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26c55d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sacrebleu_fn(label, response):\n",
    "    score = sacrebleu.compute(predictions=[response], references=[[label]])['score']\n",
    "    return 100-score \n",
    "\n",
    "def calculatePerplexity(sentence):\n",
    "     \"\"\"\n",
    "     exp(loss)\n",
    "     \"\"\"\n",
    "     input_ids = torch.tensor(tokenizer.encode(sentence)).unsqueeze(0)\n",
    "     input_ids = input_ids.to('cuda')\n",
    "     with torch.no_grad():\n",
    "         outputs = ppl_model(input_ids, labels=input_ids)\n",
    "     loss, logits = outputs[:2]\n",
    "     return torch.exp(loss)\n",
    "\n",
    "def perplexity_fn(text):\n",
    "    ppl_lst = []\n",
    "    for i in text:\n",
    "        ppl_lst.append(calculatePerplexity(i).unsqueeze(0))\n",
    "    ppl_tns = torch.cat(ppl_lst)\n",
    "    return ppl_tns, torch.mean(ppl_tns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2856c93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_fn_comp(bleu_score, label, response):\n",
    "    if config_sc['reward_type'] == 'bleu':\n",
    "        return 'bleu'\n",
    "    \n",
    "    if config_sc['reward_type'] == 'bert':\n",
    "        score = bertscore.compute(predictions=response, references=label, \n",
    "                            model_type=\"microsoft/deberta-large\", device='cuda')['f1']\n",
    "        score = [-abs(number) for number in score]\n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e111c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_sacrbleu(response, label):\n",
    "    pool = Pool()\n",
    "    result = [pool.apply(sacrebleu_fn, args=(true, pred)) for true, pred in zip(label, response)]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba486ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Seq impl\n",
    "def reward_fn(response, label, label_texts, generated_texts):\n",
    "    \n",
    "    bleu_score = reward_sacrbleu(response, label)\n",
    "        \n",
    "    ppl_lb_tns, ppl_lb_mean = perplexity_fn(label_texts)\n",
    "\n",
    "    ppl_gen_tns, ppl_gen_mean = perplexity_fn(generated_texts)\n",
    "    \n",
    "    score = reward_fn_comp(bleu_score, label, response)\n",
    "    \n",
    "    if score == 'bleu':\n",
    "        score = bleu_score\n",
    "\n",
    "    return score, bleu_score, ppl_gen_mean, ppl_lb_mean, ppl_lb_tns, ppl_gen_tns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c2da4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_data = pd.read_csv('all_train.csv')\n",
    "ds = Dataset.from_pandas(lm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e55260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d0a346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sample):\n",
    "    sample[\"tokens\"] = tokenizer.encode(sample[\"prefix\"])\n",
    "    sample[\"query\"] = tokenizer.decode(sample[\"tokens\"])\n",
    "    return sample\n",
    "\n",
    "ds = ds.map(tokenize, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaba27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_kwargs = {\n",
    "    \"min_length\":-1,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d37f259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collater(data):\n",
    "    return dict((key, [d[key] for d in data]) for key in data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "690dcb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 'train':\n",
    "    model = AutoModelForCausalLMWithValueHead.from_pretrained(\n",
    "        config.model_name,\n",
    "        device_map=\"auto\")\n",
    "\n",
    "    model_ref = AutoModelForCausalLMWithValueHead.from_pretrained(config.model_name, device_map=\"auto\")\n",
    "elif mode == 'inference':\n",
    "    model = AutoModelForCausalLMWithValueHead.from_pretrained(\n",
    "        'saved_models/',\n",
    "        device_map=\"auto\")\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained('saved_models/')\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "ppl_model = AutoModelForCausalLM.from_pretrained(config.model_name, device_map=\"auto\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae0874eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 'train':\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=config.learning_rate)\n",
    "    # We then build the PPOTrainer, passing the model, the reference model, the tokenizer\n",
    "    ppo_trainer = PPOTrainer(\n",
    "        config, model, ref_model=model_ref, tokenizer=tokenizer, dataset=ds, data_collator=collater, optimizer=optimizer\n",
    "    )\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "182c2c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(total_ppo_epochs=2):\n",
    "    for epoch, batch in tqdm(zip(range(total_ppo_epochs), iter(ppo_trainer.dataloader))):\n",
    "\n",
    "        logs, timing = dict(), dict()\n",
    "        t0 = time.time()\n",
    "        query_tensors = [torch.tensor(t).long().cuda() for t in batch[\"tokens\"]]\n",
    "\n",
    "        #### Get response from lm\n",
    "        t = time.time()\n",
    "        response_tensors = []\n",
    "        for i in range(ppo_trainer.config.batch_size):\n",
    "            gen_len = 55\n",
    "            query_tensor_sq = query_tensors[i].unsqueeze(dim=0)\n",
    "            gen_kwargs[\"max_new_tokens\"] = gen_len\n",
    "            response = ppo_trainer.generate(query_tensors[i], **gen_kwargs)\n",
    "\n",
    "            response_tensors.append(response.squeeze()[-gen_len:])\n",
    "\n",
    "        batch['response'] = [tokenizer.decode(r.squeeze()) for r in response_tensors]\n",
    "        timing['time/get_response'] = time.time()-t\n",
    "        #### Compute reward score\n",
    "        t = time.time()\n",
    "        respones_batch = batch['response']\n",
    "        label_batch = batch['suffix']\n",
    "\n",
    "        label_texts = [q + r for q,r in zip(batch['query'], batch['suffix'])]\n",
    "        generated_texts = [q + r for q,r in zip(batch['query'], batch['response'])]\n",
    "\n",
    "        reward_scores, bleu_score, mean_ppl_gen, mean_ppl_label, perplexity_scores_label, perplexity_scores_generated = reward_fn(respones_batch, label_batch, label_texts, generated_texts)\n",
    "        rewards = torch.tensor(reward_scores, dtype=float).cuda()\n",
    "        rewards = [torch.tensor(output) for output in rewards]\n",
    "\n",
    "        timing['time/get_sentiment_preds'] = time.time()-t\n",
    "        print('finished reward', rewards)\n",
    "        #### Run PPO step \n",
    "        t = time.time()\n",
    "\n",
    "        model.gradient_checkpointing_enable()\n",
    "        model.pretrained_model.config.use_cache = False\n",
    "\n",
    "\n",
    "        stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n",
    "        ppo_trainer.log_stats(stats, batch, rewards)\n",
    "\n",
    "\n",
    "        timing['time/optimization'] = time.time()-t\n",
    "\n",
    "        #### Log everything\n",
    "        timing['time/epoch'] = time.time()-t0\n",
    "        rewards = torch.tensor(reward_scores, dtype=float)\n",
    "        table_rows = [list(r) for r in zip(batch['query'], batch['response'], rewards.cpu().tolist(), batch['suffix'], \n",
    "                                           perplexity_scores_label.cpu().tolist(), \n",
    "                                           perplexity_scores_generated.cpu().tolist(), bleu_score)]\n",
    "\n",
    "        logs.update({'game_log': wandb.Table(columns=['query', 'pred', 'reward','label','perplexity_label',\n",
    "                                                     'perplexity_response', 'bleu_score'], rows=table_rows)})\n",
    "        logs.update(timing)\n",
    "    #     logs.update(stats)\n",
    "        logs['env/reward_mean'] = torch.mean(rewards).cpu().numpy()\n",
    "        logs['env/reward_std'] = torch.std(rewards).cpu().numpy()\n",
    "        logs['env/perplexity_gen'] = mean_ppl_gen.cpu().numpy()\n",
    "        logs['env/perplexity_lab'] = mean_ppl_label.cpu().numpy()\n",
    "        logs['env/bleu'] = statistics.mean(bleu_score)\n",
    "        logs['env/reward_dist'] = rewards.cpu().numpy()\n",
    "\n",
    "        ppo_trainer.accelerator.log(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba37dfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(total_ppo_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75b1be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('saved_models/', max_shard_size='20GB')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
